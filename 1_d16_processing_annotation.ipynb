{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os, scipy\n",
    "import anndata\n",
    "from typing import Dict, Optional\n",
    "import tables\n",
    "import scipy.sparse as sp\n",
    "import scvelo as scv\n",
    "import scanpy.external as sce\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# R interfacezziI8a\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects import r\n",
    "import rpy2.rinterface_lib.callbacks\n",
    "import anndata2ri\n",
    "import rpy2.robjects.numpy2ri\n",
    "#import numpy2ri\n",
    "\n",
    "pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523edf59",
   "metadata": {},
   "source": [
    "# Read CellBender output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b534c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_h5(file: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Read in everything from an h5 file and put into a dictionary.\n",
    "\n",
    "    Args:\n",
    "        file: The h5 file\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing all the information from the h5 file\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    with tables.open_file(file) as f:\n",
    "        # read in everything\n",
    "        for array in f.walk_nodes(\"/\", \"Array\"):\n",
    "            d[array.name] = array.read()\n",
    "    return d\n",
    "\n",
    "def _fill_adata_slots_automatically(adata, d):\n",
    "    \"\"\"Add other information to the adata object in the appropriate slot.\"\"\"\n",
    "\n",
    "    # TODO: what about \"features_analyzed_inds\"?  If not all features are analyzed, does this work?\n",
    "\n",
    "    for key, value in d.items():\n",
    "        try:\n",
    "            if value is None:\n",
    "                continue\n",
    "            value = np.asarray(value)\n",
    "            if len(value.shape) == 0:\n",
    "                adata.uns[key] = value\n",
    "            elif value.shape[0] == adata.shape[0]:\n",
    "                if (len(value.shape) < 2) or (value.shape[1] < 2):\n",
    "                    adata.obs[key] = value\n",
    "                else:\n",
    "                    adata.obsm[key] = value\n",
    "            elif value.shape[0] == adata.shape[1]:\n",
    "                if value.dtype.name.startswith('bytes'):\n",
    "                    adata.var[key] = value.astype(str)\n",
    "                else:\n",
    "                    adata.var[key] = value\n",
    "            else:\n",
    "                adata.uns[key] = value\n",
    "        except Exception:\n",
    "            print('Unable to load data into AnnData: ', key, value, type(value))\n",
    "\n",
    "def anndata_from_h5(file: str,\n",
    "                    analyzed_barcodes_only: bool = True) -> anndata.AnnData:\n",
    "    \"\"\"Load an output h5 file into an AnnData object for downstream work.\n",
    "\n",
    "    Args:\n",
    "        file: The h5 file\n",
    "        analyzed_barcodes_only: False to load all barcodes, so that the size of\n",
    "            the AnnData object will match the size of the input raw count matrix.\n",
    "            True to load a limited set of barcodes: only those analyzed by the\n",
    "            algorithm. This allows relevant latent variables to be loaded\n",
    "            properly into adata.obs and adata.obsm, rather than adata.uns.\n",
    "\n",
    "    Returns:\n",
    "        anndata.AnnData: The anndata object, populated with inferred latent variables\n",
    "            and metadata.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    d = dict_from_h5(file)\n",
    "    X = sp.csc_matrix((d.pop('data'), d.pop('indices'), d.pop('indptr')),\n",
    "                      shape=d.pop('shape')).transpose().tocsr()\n",
    "\n",
    "    # check and see if we have barcode index annotations, and if the file is filtered\n",
    "    barcode_key = [k for k in d.keys() if (('barcode' in k) and ('ind' in k))]\n",
    "    if len(barcode_key) > 0:\n",
    "        max_barcode_ind = d[barcode_key[0]].max()\n",
    "        filtered_file = (max_barcode_ind >= X.shape[0])\n",
    "    else:\n",
    "        filtered_file = True\n",
    "\n",
    "    if analyzed_barcodes_only:\n",
    "        if filtered_file:\n",
    "            # filtered file being read, so we don't need to subset\n",
    "            print('Assuming we are loading a \"filtered\" file that contains only cells.')\n",
    "            pass\n",
    "        elif 'barcode_indices_for_latents' in d.keys():\n",
    "            X = X[d['barcode_indices_for_latents'], :]\n",
    "            d['barcodes'] = d['barcodes'][d['barcode_indices_for_latents']]\n",
    "        elif 'barcodes_analyzed_inds' in d.keys():\n",
    "            X = X[d['barcodes_analyzed_inds'], :]\n",
    "            d['barcodes'] = d['barcodes'][d['barcodes_analyzed_inds']]\n",
    "        else:\n",
    "            print('Warning: analyzed_barcodes_only=True, but the key '\n",
    "                  '\"barcodes_analyzed_inds\" or \"barcode_indices_for_latents\" '\n",
    "                  'is missing from the h5 file. '\n",
    "                  'Will output all barcodes, and proceed as if '\n",
    "                  'analyzed_barcodes_only=False')\n",
    "\n",
    "    # Construct the anndata object.\n",
    "    adata = anndata.AnnData(X=X,\n",
    "                            obs={'barcode': d.pop('barcodes').astype(str)},\n",
    "                            var={'gene_name': (d.pop('gene_names') if 'gene_names' in d.keys()\n",
    "                                               else d.pop('name')).astype(str)},\n",
    "                            dtype=X.dtype)\n",
    "    adata.obs.set_index('barcode', inplace=True)\n",
    "    adata.var.set_index('gene_name', inplace=True)\n",
    "\n",
    "    # For CellRanger v2 legacy format, \"gene_ids\" was called \"genes\"... rename this\n",
    "    if 'genes' in d.keys():\n",
    "        d['id'] = d.pop('genes')\n",
    "\n",
    "    # For purely aesthetic purposes, rename \"id\" to \"gene_id\"\n",
    "    if 'id' in d.keys():\n",
    "        d['gene_id'] = d.pop('id')\n",
    "\n",
    "    # If genomes are empty, try to guess them based on gene_id\n",
    "    if 'genome' in d.keys():\n",
    "        if np.array([s.decode() == '' for s in d['genome']]).all():\n",
    "            if '_' in d['gene_id'][0].decode():\n",
    "                print('Genome field blank, so attempting to guess genomes based on gene_id prefixes')\n",
    "                d['genome'] = np.array([s.decode().split('_')[0] for s in d['gene_id']], dtype=str)\n",
    "\n",
    "    # Add other information to the anndata object in the appropriate slot.\n",
    "    _fill_adata_slots_automatically(adata, d)\n",
    "\n",
    "    # Add a special additional field to .var if it exists.\n",
    "    if 'features_analyzed_inds' in adata.uns.keys():\n",
    "        adata.var['cellbender_analyzed'] = [True if (i in adata.uns['features_analyzed_inds'])\n",
    "                                            else False for i in range(adata.shape[1])]\n",
    "    elif 'features_analyzed_inds' in adata.var.keys():\n",
    "        adata.var['cellbender_analyzed'] = [True if (i in adata.var['features_analyzed_inds'].values)\n",
    "                                            else False for i in range(adata.shape[1])]\n",
    "\n",
    "    if analyzed_barcodes_only:\n",
    "        for col in adata.obs.columns[adata.obs.columns.str.startswith('barcodes_analyzed')\n",
    "                                     | adata.obs.columns.str.startswith('barcode_indices')]:\n",
    "            try:\n",
    "                del adata.obs[col]\n",
    "            except Exception:\n",
    "                pass\n",
    "    else:\n",
    "        # Add a special additional field to .obs if all barcodes are included.\n",
    "        if 'barcodes_analyzed_inds' in adata.uns.keys():\n",
    "            adata.obs['cellbender_analyzed'] = [True if (i in adata.uns['barcodes_analyzed_inds'])\n",
    "                                                else False for i in range(adata.shape[0])]\n",
    "        elif 'barcodes_analyzed_inds' in adata.obs.keys():\n",
    "            adata.obs['cellbender_analyzed'] = [True if (i in adata.obs['barcodes_analyzed_inds'].values)\n",
    "                                                else False for i in range(adata.shape[0])]\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a12920",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata_from_h5('CellBender/d16_cellbender_output_file.h5')\n",
    "adata.obs.index.name = None\n",
    "adata.var.index.name = None\n",
    "adata.X = adata.X.astype(np.float64)\n",
    "del adata.uns\n",
    "del adata.obsm\n",
    "adata.layers['counts'] = adata.X\n",
    "adata.var_names_make_unique()\n",
    "\n",
    "adata_var_meta = adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde69c23",
   "metadata": {},
   "source": [
    "# Sample assignment (HTO calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a255c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(dplyr)\n",
    "library(assertthat)\n",
    "library(ggplot2)\n",
    "library(mclust)\n",
    "library(diptest)\n",
    "library(intrinsicDimension)\n",
    "\n",
    "HTODemux.mcl <- function(object, assay = \"HTO\", q_l = 1, q_h = 0.005, seed = 42){\n",
    "  # A function to find the threshold for each hastag, the P, and singlet, doublets and negative.\n",
    "  # The input is the HTO data matrix (normalized across cells).\n",
    "  \n",
    "  assay <- assay %||% DefaultAssay(object = object)\n",
    "  data <- GetAssayData(object = object, assay = assay, slot = 'data')\n",
    "  hto.cutoff.metadata = data.frame(cut_off = future.apply::future_apply(data,1,function(x) select_hash_cutoff_mcl(x, q_l = q_l, q_h = q_h), future.seed = T))\n",
    "  hto.cutoff.metadata$Multi_modal = apply(data,1,function(x) is_multimodal(x))\n",
    "  hto_mcl.p = t(apply(data,1,function(x) hash_mcl_p(x, seed = seed, q_l = q_l, q_h = q_h)))\n",
    "  discrete <- data\n",
    "  discrete[discrete > 0] <- 0\n",
    "  for (iter in rownames(x = data)) {\n",
    "    values <- data[iter, ]\n",
    "    cutoff <- hto.cutoff.metadata[iter,'cut_off']\n",
    "    discrete[iter, names(x = which(x = values > cutoff))] <- 1\n",
    "  }\n",
    "  classification.metadata <- HTO_classifcation(discrete, hto_mcl.p, assay)\n",
    "  object <- AddMetaData(object = object, metadata = classification.metadata)\n",
    "  Idents(object) <- paste(assay, \"calledFeatures\", sep = '_')\n",
    "  doublets <- rownames(x = object[[]])[which(object[[paste(assay, 'globalClass', sep = \"_\")]] == \"Doublet\")]\n",
    "  Idents(object = object, cells = doublets) <- \"Doublet\"\n",
    "  Idents(object) = factor(Idents(object), levels = c('Doublet', 'Negative', rownames(object@assays$HTO)))\n",
    "  object$sampleID <- Idents(object = object)\n",
    "  return(object)\n",
    "}\n",
    "\n",
    "is_multimodal <- function(x, p.cutoff = 1e-2) {\n",
    "  # Test if the expression distribution violates unimodal distribution.\n",
    "  p = diptest::dip.test(x)$p.value\n",
    "  return(p < p.cutoff)\n",
    "}\n",
    "\n",
    "select_hash_cutoff_mcl <- function(x, q_l = 1, q_h = 0.01, seed = 42) {\n",
    "  # Model HTO data as a mixture of two Gaussian distributions (for normalized [across cells] data)\n",
    "  # And select HTO cutoff based on mclust (Model based clustering).\n",
    "  assertthat::assert_that(class(x) == \"numeric\")\n",
    "  assertthat::is.number(seed)\n",
    "  assertthat::assert_that(length(seed) == 1)\n",
    "  set.seed(seed)\n",
    "  km <- mclust::Mclust(data = x, G = 2, verbose = F)\n",
    "  cl <- km$classification\n",
    "  cl_center = km$parameters$mean\n",
    "  high_cl <- which(cl_center == max(cl_center))\n",
    "  low_cl <- which(cl_center != max(cl_center))\n",
    "  # q_l and q_h are the quantiles for negative and postive cluster, respectively. \n",
    "  cutoff <- max(quantile(x[cl == low_cl], q_l), quantile(x[cl == high_cl], q_h))\n",
    "  # The higher the cut off, the less false positive (the more false negative).\n",
    "  return(cutoff)\n",
    "}\n",
    "\n",
    "hash_mcl_p <- function(x, seed = 3030, q_l = 1, q_h = 0.001) {\n",
    "  assertthat::assert_that(class(x) == \"numeric\")\n",
    "  assertthat::is.number(seed)\n",
    "  assertthat::assert_that(length(seed) == 1)\n",
    "  set.seed(seed)\n",
    "  km <- mclust::Mclust(data = x, G = 2, verbose = F)\n",
    "  cl <- km$classification\n",
    "  cl_center = km$parameters$mean\n",
    "  high_cl <- which(cl_center == max(cl_center))\n",
    "  low_cl <- which(cl_center != max(cl_center))\n",
    "  p.high_cl <- km$z[,high_cl]\n",
    "  # Correct assignment error from Mclust\n",
    "  p.high_cl[which(x < max(quantile(cl_center[low_cl], q_l), quantile(cl_center[low_cl], q_h)))] = 0\n",
    "  names(p.high_cl) = names(x)\n",
    "  return(p.high_cl)\n",
    "}\n",
    "\n",
    "HTO_classifcation = function(discrete, hto_mcl.p, assay){\n",
    "  # Based on HTODemux (Seurat)\n",
    "  npositive <- colSums(x = discrete)\n",
    "  classification.global <- npositive\n",
    "  classification.global[npositive == 0] <- \"Negative\"\n",
    "  classification.global[npositive == 1] <- \"Singlet\"\n",
    "  classification.global[npositive > 1] <- \"Doublet\"\n",
    "  donor.id = rownames(x = discrete)\n",
    "  hash.max <- apply(X = hto_mcl.p, MARGIN = 2, FUN = max) # This returns the probability of the most likely HashID (based on the Hashtag distribution among cells)\n",
    "  hash.maxID <- as.character(donor.id[apply(X = hto_mcl.p, MARGIN = 2, FUN = which.max)])\n",
    "  hash.second <- apply(X = hto_mcl.p, MARGIN = 2, FUN = function(x) sort(x,decreasing = T)[2])\n",
    "  hash.secondID <- as.character(donor.id[apply(X = hto_mcl.p, MARGIN = 2, FUN = function(x) order(x,decreasing = T)[2])])\n",
    "  hash.margin <- hash.max - hash.second\n",
    "  doublet_id <- sapply(X = 1:length(x = hash.maxID), FUN = function(x) {\n",
    "    return(paste(sort(x = c(hash.maxID[x], hash.secondID[x])), \n",
    "                 collapse = \"_\"))\n",
    "  })\n",
    "  classification <- classification.global\n",
    "  classification[classification.global == \"Negative\"] <- \"Negative\"\n",
    "  classification[classification.global == \"Singlet\"] <- hash.maxID[which(x = classification.global == \"Singlet\")]\n",
    "  classification[classification.global == \"Doublet\"] <- doublet_id[which(x = classification.global == \"Doublet\")]\n",
    "  classification.metadata <- data.frame(hash.maxID, hash.secondID, hash.margin, classification, classification.global)\n",
    "  colnames(x = classification.metadata) <- paste(assay, c(\"primaryID\", \"secondaryID\", \"margin\", \"calledFeatures\", \"globalClass\"), sep = \"_\")\n",
    "  return(classification.metadata)\n",
    "}\n",
    "\n",
    "        \n",
    "                                               \n",
    "my.cols <- c('Doublet' = '#E56786','Negative' = '#0000FF','Singlet' = '#7E9D00',\n",
    "             'Called' = '#C1E24D','Uncalled' = '#FFB2FF', 'intra-doublet' = '#FFA500',\n",
    "             'Highlight' = '#de3163','Lowlight' = '#f4b8c9','Greyneric' = '#878686')\n",
    "\n",
    "base.size = 10\n",
    "plotting.font <- 'Helvetica'\n",
    "\n",
    "exponent_format <- function() {\n",
    "  function(x) {\n",
    "    parse(text = gsub(\"e\\\\+?\", \" %*% 10^\", scales::scientific_format()(x)))\n",
    "  }\n",
    "}\n",
    "\n",
    "make_plot_htoThresh <- function(hto.sample.calling.metadata, hto.cutoff.metadata, index) {\n",
    "  \n",
    "  hto.cutoff.metadata[['hto']] <- hto.cutoff.metadata[['hto_name']]\n",
    "  \n",
    "  p <- ggplot(hto.sample.calling.metadata, aes(x = expression, fill = above_cutoff)) +\n",
    "    geom_histogram(bins = 100) +\n",
    "    facet_wrap(~sample_id, scales = 'free',ncol = 3) +\n",
    "    xlab('Expression (CLR-norm)') +\n",
    "    ylab('UMI counts (HTO)') +\n",
    "    scale_y_log10(labels = exponent_format()) +\n",
    "    scale_fill_manual(name = '',\n",
    "                      labels = c('HTO negative','HTO positive'),\n",
    "                      values = c(my.cols[['Uncalled']],my.cols[['Called']]),\n",
    "                      guide = guide_legend(override.aes = list(fill = c(my.cols[['Uncalled']],my.cols[['Called']])))) +\n",
    "    ggtitle(index) +\n",
    "    theme_minimal(base_size = base.size) +\n",
    "    theme(text = element_text(family = plotting.font), legend.position = 'bottom')\n",
    "  \n",
    "  p <- patchwork::wrap_plots(p)\n",
    "  return(p)\n",
    "}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i adata -o adata_hto\n",
    "\n",
    "Csparse_validate = \"CsparseMatrix_validate\"\n",
    "library(Seurat)\n",
    "library(Matrix)\n",
    "library(scater)\n",
    "library(scran)\n",
    "library(scDblFinder)\n",
    "library(PCAtools)\n",
    "\n",
    "hto_matrix_dir = \"Cite_seq_count_d16/umi_count/\"\n",
    "barcode.path <- paste0(hto_matrix_dir, \"barcodes.tsv.gz\")\n",
    "features.path <- paste0(hto_matrix_dir, \"features.tsv.gz\")\n",
    "matrix.path <- paste0(hto_matrix_dir, \"matrix.mtx.gz\")\n",
    "hto_matrix <- readMM(file = matrix.path)\n",
    "feature.names = read.delim(features.path, header = FALSE, stringsAsFactors = FALSE)\n",
    "barcode.names = read.delim(barcode.path, header = FALSE, stringsAsFactors = FALSE)\n",
    "colnames(hto_matrix) = barcode.names$V1\n",
    "rownames(hto_matrix) = feature.names$V1\n",
    "# Removing the unmapped feature from the HTO matrix\n",
    "hto_matrix <- hto_matrix[!(rownames(hto_matrix) %in% 'unmapped'),]\n",
    "\n",
    "\n",
    "\n",
    "sobj <- as.Seurat(adata, counts='counts', data=NULL)\n",
    "\n",
    "# Ensure similar naming pattern between the colnames in hto and transcriptome matrix\n",
    "colnames(hto_matrix) <- paste(colnames(hto_matrix), \"-1\", sep=\"\")\n",
    "\n",
    "# Select cell barcodes detected by both RNA and HTO \n",
    "joint_barcodes <- intersect(colnames(sobj), colnames(hto_matrix))\n",
    "\n",
    "# Subset RNA and HTO counts by joint cell barcodes\n",
    "sobj = subset(sobj, cells=joint_barcodes)\n",
    "hto_matrix <- hto_matrix[, joint_barcodes]\n",
    "\n",
    "# Add HTO data as a new assay independent from RNA\n",
    "sobj[[\"HTO\"]] <- CreateAssayObject(counts = hto_matrix)\n",
    "\n",
    "# Normalize HTO data, here we use centered log-ratio (CLR) transformation\n",
    "sobj <- NormalizeData(sobj, assay = \"HTO\", normalization.method = \"CLR\", margin=2)\n",
    "\n",
    "\n",
    "q_l <- 1\n",
    "q_h <- 0.001\n",
    "\n",
    "\n",
    "sobj <- HTODemux.mcl(sobj, q_l = q_l, q_h = q_h)   \n",
    "\n",
    "\n",
    "# Plotting\n",
    "tmp.assay <- DefaultAssay(object = sobj)\n",
    "tmp.data <- GetAssayData(object = sobj, assay = 'HTO', slot = 'data')\n",
    "hto.data.wide = data.frame(t(tmp.data))\n",
    "colnames(hto.data.wide) <- gsub(\"[.]\", \"-\", colnames(hto.data.wide), perl = T)\n",
    "hto.data.long = data.table::melt(data.table::setDT(hto.data.wide,keep.rownames = T), id.vars = 'rn', value.name = 'expression',variable.name = 'sample_id')\n",
    "#hto.data.long <- rename(hto.data.long, 'CB' = 'rn')\n",
    "hto.data.long[, sample_id := as.character(sample_id)]\n",
    "\n",
    "hto_mcl.cutoff = data.table::data.table(cut_off = future.apply::future_apply(tmp.data,1,function(x) select_hash_cutoff_mcl(x, q_l = q_l, q_h = q_h), future.seed = T), hto_name = colnames(hto.data.wide)[-1], key = \"hto_name\")\n",
    "hto.data.long[, above_cutoff := expression > hto_mcl.cutoff[sample_id, cut_off]]\n",
    "\n",
    "hto.sample.calling.metadata <- hto.data.long\n",
    "hto.cutoff.metadata <- hto_mcl.cutoff\n",
    "\n",
    "p.hto.barcode.calling <- make_plot_htoThresh(hto.sample.calling.metadata,hto.cutoff.metadata, 'd16')\n",
    "print(p.hto.barcode.calling)\n",
    "\n",
    "adata_hto = as.SingleCellExperiment(sobj)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16368771",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cells = list(set(adata.obs_names) & set(adata_hto.obs_names))\n",
    "adata = adata[common_cells].copy()\n",
    "adata.obs['sampleID'] = adata_hto.obs['sampleID']\n",
    "adata.obs['nCount_HTO'] = adata_hto.obs['nCount_HTO']\n",
    "adata.obs['nFeature_HTO'] = adata_hto.obs['nFeature_HTO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126229fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(Rtsne)\n",
    "\n",
    "process_seur <- function(seur, n.pca.dims = 50, assay = 'originalexp', verbose = F) {\n",
    "  cat('#\\t..\\tprocessing ',assay,'-assay..\\n', sep = '')\n",
    "  suppressWarnings({\n",
    "    if (assay == 'originalexp') {\n",
    "      cat('#\\t..\\t\\trunning sctransform..\\n')\n",
    "      seur <- SCTransform(seur, assay = 'originalexp', method = 'qpoisson', verbose = verbose)\n",
    "      cat('#\\t..\\t\\trunning PCA..\\n')\n",
    "      seur <- RunPCA(seur, assay = 'SCT', verbose = verbose)\n",
    "      cat('#\\t..\\t\\testimating global dims..\\n')\n",
    "      dims <- round(\n",
    "        as.numeric(\n",
    "          maxLikGlobalDimEst(\n",
    "            data = seur@reductions[['pca']][, 1:n.pca.dims],\n",
    "            k = 20)))\n",
    "      cat('#\\t..\\t\\t\\tdims:\\t',dims,'\\n')\n",
    "      cat('#\\t..\\t\\trunning tSNE..\\n')\n",
    "      seur <- RunTSNE(seur, assay = 'SCT', dims = seq(dims), verbose = verbose, check_duplicates = FALSE)\n",
    "      cat('#\\t..\\t\\trunning UMAP..\\n')\n",
    "      seur <- RunUMAP(seur, assay = 'SCT', dims = seq(dims), verbose = verbose)\n",
    "      cat('#\\t..\\t\\trunning FindNeighbors..\\n')\n",
    "      seur <- FindNeighbors(seur, assay = 'SCT', dims = seq(dims), verbose = verbose)\n",
    "      cat('#\\t..\\t\\trunning FindClusters..\\n')\n",
    "      seur <- FindClusters(seur, assay = 'SCT', verbose = verbose)\n",
    "    }\n",
    "    if (assay == 'HTO') {\n",
    "      cat('#\\t..\\t\\trunning PCA..\\n')\n",
    "      seur <- ScaleData(seur,\n",
    "                        assay = 'HTO',\n",
    "                        features = rownames(seur[['HTO']]@counts),\n",
    "                        verbose = verbose)\n",
    "      seur <- RunPCA(seur,\n",
    "                     assay = 'HTO',\n",
    "                     features = rownames(seur[['HTO']]@counts),\n",
    "                     reduction.name = 'hto.pca',\n",
    "                     reduction.key = 'htoPC_',\n",
    "                     approx=FALSE,\n",
    "                     verbose = verbose)\n",
    "      \n",
    "      cat('#\\t..\\t\\trunning tSNE..\\n')\n",
    "      seur <- RunTSNE(seur,\n",
    "                      distance.matrix = as.matrix(dist(t(GetAssayData(object = seur, assay = 'HTO')))),\n",
    "                      reduction.name = 'hto.tsne',\n",
    "                      reduction.key = 'htotSNE_',\n",
    "                      verbose = verbose,\n",
    "                      check_duplicates = FALSE)\n",
    "      \n",
    "      cat('#\\t..\\t\\trunning UMAP..\\n')\n",
    "      seur <- RunUMAP(seur,\n",
    "                      reduction = \"hto.pca\",\n",
    "                      dims = seq(rownames(seur@assays$HTO)),\n",
    "                      reduction.name = 'hto.umap',\n",
    "                      reduction.key = 'htoUMAP_',\n",
    "                      metric='correlation',\n",
    "                      verbose = verbose)\n",
    "    }\n",
    "  })\n",
    "  return(seur)\n",
    "}\n",
    "\n",
    "make_plot_htotsne <- function(meta.data) {\n",
    "    tmp.color.palette <- c(my.cols[['Doublet']],\n",
    "                           my.cols[['Negative']],\n",
    "                           my.cols[['Singlet']],\n",
    "                           my.cols[['intra-doublet']])\n",
    "\n",
    "    p <- ggplot(meta.data) +\n",
    "      geom_point(aes(x = HTO_tsne1, y = HTO_tsne2, col = HTO_globalClass, alpha = .25)) +\n",
    "      scale_color_manual(values = tmp.color.palette) +\n",
    "      labs(x = 'tSNE 1', y = 'tSNE 2', color = 'HTO classification') +\n",
    "      theme_minimal(base_size = base.size) +\n",
    "      guides(alpha = 'none') +\n",
    "      theme(text = element_text(family = plotting.font), legend.position = 'bottom') \n",
    "    \n",
    "\n",
    "    p <- patchwork::wrap_plots(p)\n",
    "    return(p)\n",
    "}\n",
    "\n",
    "dub_cutoff <- function(x) {\n",
    "  \n",
    "  # calculate number of neighbors at each proportion that are doublets\n",
    "  data.frame(\"proportion\" = x$RNA_doubletNeighborProportion) %>% \n",
    "    group_by(proportion) %>% \n",
    "    summarize(n_cells = n()) %>% \n",
    "    mutate(pct_cells = n_cells / sum(n_cells)) -> data \n",
    "  \n",
    "  \n",
    "  # find point at which we gain very few doublets as proportion increases \n",
    "  cut <- data$proportion[PCAtools::findElbowPoint(variance = sort(data$n_cells, decreasing = T)) + 1]\n",
    "  vec <- if_else(x$RNA_doubletNeighborProportion <= cut, F, T)\n",
    "  \n",
    "  data[['cut']] <- cut\n",
    "  \n",
    "  \n",
    "  return(vec)\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sobj_temp <- subset(x = sobj,subset=nCount_originalexp > 0)\n",
    "\n",
    "# identify intra-hash doublets                                                                             \n",
    "sobj_temp <- process_seur(sobj_temp,assay = 'HTO')\n",
    "\n",
    "sce.full <- as.SingleCellExperiment(sobj_temp)\n",
    "sce.full <- logNormCounts(sce.full)\n",
    "dec.hash <- modelGeneVar(sce.full)\n",
    "\n",
    "top.hash <- getTopHVGs(dec.hash, n = 1000)\n",
    "sce.full <- runPCA(sce.full, subset_row = top.hash, ncomponents = 20)\n",
    "sce.full[['HTO_doubletBool']] <- if_else(sce.full[['sampleID']] == 'Doublet', true = T, false = F)\n",
    "\n",
    "\n",
    "# Recovering the intra-sample doublets:\n",
    "cat('#\\t..\\trecovering intra-sample doublets..\\n')\n",
    "hashed.doublets <- scDblFinder::recoverDoublets(sce.full,\n",
    "                                              use.dimred = 'PCA',\n",
    "                                              doublets = sce.full[['HTO_doubletBool']],\n",
    "                                              samples = table(sce.full[['sampleID']]))\n",
    "\n",
    "sce.full[['RNA_doubletNeighborProportion']] <- hashed.doublets[['proportion']]\n",
    "sce.full[['RNA_recoveredDoubletBool']] <- hashed.doublets[['predicted']]\n",
    "\n",
    "cat('#\\t..\\trecovering doublet neighbors..\\n')\n",
    "sce.full[['RNA_doubletNeighborBool']] <- dub_cutoff(sce.full)\n",
    "\n",
    "sobj_temp[['HTO_doubletBool']] <- sce.full[['HTO_doubletBool']]\n",
    "sobj_temp[['RNA_recoveredDoubletBool']] <- sce.full[['RNA_recoveredDoubletBool']]\n",
    "sobj_temp[['RNA_doubletNeighborBool']] <- sce.full[['RNA_doubletNeighborBool']]\n",
    "sobj_temp[['RNA_doubletNeighborProportion']] <- sce.full[['RNA_doubletNeighborProportion']]\n",
    "\n",
    "sobj_temp[['HTO_globalClass']][sobj_temp[['RNA_recoveredDoubletBool']] == T] <- 'intra-doublet'  \n",
    "#sobj[['sampleID']][sobj[['RNA_recoveredDoubletBool']] == T] <- 'intra-doublet'                                                                              \n",
    "\n",
    "\n",
    "sobj_temp <- process_seur(sobj_temp, assay = 'originalexp')\n",
    "\n",
    "sobj_temp[['SCT_tsne1']] <- sobj_temp@reductions$tsne@cell.embeddings[,1]\n",
    "sobj_temp[['SCT_tsne2']] <- sobj_temp@reductions$tsne@cell.embeddings[,2]\n",
    "sobj_temp[['SCT_umap1']] <- sobj_temp@reductions$umap@cell.embeddings[,1]\n",
    "sobj_temp[['SCT_umap2']] <- sobj_temp@reductions$umap@cell.embeddings[,2]\n",
    "\n",
    "\n",
    "sobj_temp[['HTO_tsne1']] <- sobj_temp@reductions$hto.tsne@cell.embeddings[,1]\n",
    "sobj_temp[['HTO_tsne2']] <- sobj_temp@reductions$hto.tsne@cell.embeddings[,2]\n",
    "sobj_temp[['HTO_umap1']] <- sobj_temp@reductions$hto.umap@cell.embeddings[,1]\n",
    "sobj_temp[['HTO_umap2']] <- sobj_temp@reductions$hto.umap@cell.embeddings[,2]\n",
    "\n",
    "seurat_unfiltered_metadata <- sobj_temp[[c('sampleID','nCount_RNA','nFeature_RNA','nCount_HTO','nFeature_HTO','nCount_spliced','nFeature_spliced','nCount_unspliced','nFeature_unspliced','nCount_SCT','nFeature_SCT','HTO_primaryID','HTO_secondaryID','HTO_margin','HTO_calledFeatures','HTO_globalClass','HTO_doubletBool','RNA_recoveredDoubletBool','RNA_doubletNeighborBool','RNA_doubletNeighborProportion','seurat_clusters','SCT_tsne1','SCT_tsne2','SCT_umap1','SCT_umap2','HTO_tsne1','HTO_tsne2','HTO_umap1','HTO_umap2')]]   \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print(paste0('Number of intra-doublets : ',table(seurat_unfiltered_metadata[['HTO_globalClass']])[['intra-doublet']]))\n",
    "make_plot_htotsne(seurat_unfiltered_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "Idents(sobj) <- \"HTO_globalClass\"\n",
    "VlnPlot(sobj, features = \"nCount_originalexp\", pt.size = 0, log = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c63062",
   "metadata": {},
   "source": [
    "# Aggregate spliced/unspliced counts to adata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildAnndataFromStarCurr(path):\n",
    "    \"\"\"Generate an anndata object from the STAR aligner output folder\"\"\"\n",
    "    path=path\n",
    "    # Load Read Counts\n",
    "    X = sc.read_mtx(path+'Gene/raw/matrix.mtx')\n",
    "\n",
    "    # Transpose counts matrix to have Cells as rows and Genes as cols as expected by AnnData objects\n",
    "    X = X.X.transpose()\n",
    "\n",
    "    # Load the 3 matrices containing Spliced, Unspliced and Ambigous reads\n",
    "    mtxU = np.loadtxt(path+'Velocyto/raw/unspliced.mtx', skiprows=3, delimiter=' ')\n",
    "    mtxS = np.loadtxt(path+'Velocyto/raw/spliced.mtx', skiprows=3, delimiter=' ')\n",
    "    mtxA = np.loadtxt(path+'Velocyto/raw/ambiguous.mtx', skiprows=3, delimiter=' ')\n",
    "\n",
    "    # Extract sparse matrix shape informations from the third row\n",
    "    shapeU = np.loadtxt(path+'Velocyto/raw/unspliced.mtx', skiprows=2, max_rows = 1 ,delimiter=' ')[0:2].astype(int)\n",
    "    shapeS = np.loadtxt(path+'Velocyto/raw/spliced.mtx', skiprows=2, max_rows = 1 ,delimiter=' ')[0:2].astype(int)\n",
    "    shapeA = np.loadtxt(path+'Velocyto/raw/ambiguous.mtx', skiprows=2, max_rows = 1 ,delimiter=' ')[0:2].astype(int)\n",
    "\n",
    "    # Read the sparse matrix with csr_matrix((data, (row_ind, col_ind)), shape=(M, N))\n",
    "    # Subract -1 to rows and cols index because csr_matrix expects a 0 based index\n",
    "    # Traspose counts matrix to have Cells as rows and Genes as cols as expected by AnnData objects\n",
    "\n",
    "    spliced = sp.csr_matrix((mtxS[:,2], (mtxS[:,0]-1, mtxS[:,1]-1)), shape = shapeS).transpose()\n",
    "    unspliced = sp.csr_matrix((mtxU[:,2], (mtxU[:,0]-1, mtxU[:,1]-1)), shape = shapeU).transpose()\n",
    "    ambiguous = sp.csr_matrix((mtxA[:,2], (mtxA[:,0]-1, mtxA[:,1]-1)), shape = shapeA).transpose()\n",
    "\n",
    "    # Load Genes and Cells identifiers\n",
    "    obs = pd.read_csv(path+'Velocyto/raw/barcodes.tsv',\n",
    "                  header = None, index_col = 0)\n",
    "\n",
    "    # Remove index column name to make it compliant with the anndata format\n",
    "    obs.index.name = None\n",
    "\n",
    "    var = pd.read_csv(path+'Velocyto/raw/features.tsv', sep='\\t',\n",
    "                                    names = ('gene_ids', 'feature_types'), index_col = 1)\n",
    "  \n",
    "    # Build AnnData object to be used with ScanPy and ScVelo\n",
    "    adata = anndata.AnnData(X = X, obs = obs, var = var,\n",
    "                                                 layers = {'spliced': spliced, 'unspliced': unspliced, 'ambiguous': ambiguous})\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    return adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliced_adata = buildAnndataFromStarCurr(\"Starsolo/Solo.out/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the barcode naming pattern is consistent between datasets \n",
    "spliced_adata.obs_names = [barcode + '-1' for barcode in spliced_adata.obs_names]\n",
    "print(adata.shape)\n",
    "print(spliced_adata.shape)\n",
    "# Subset so that both datasets contains same barcodes\n",
    "spliced_adata = spliced_adata[spliced_adata.obs_names.isin(adata.obs_names)]\n",
    "\n",
    "print(list(set(spliced_adata.var_names)-set(adata.var_names)))\n",
    "\n",
    "adata = scv.utils.merge(adata, spliced_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d6d36-5080-4551-aba9-7707f799b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040db2c-9882-42a2-900d-133e702dab42",
   "metadata": {},
   "source": [
    "# QC and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[~adata.obs['sampleID'].isin([\"Doublet\", \"Negative\"])]\n",
    "#adata.var = adata_var_meta.loc[list(set(adata_var_meta.index) & set(adata.var_names))]\n",
    "\n",
    "# remove hashtag from the sample id\n",
    "adata.obs['sampleID'] = adata.obs['sampleID'].map(lambda x:x[0:x.rfind('-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990bc61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add diff protocol, timepoint, and condition to pandas df\n",
    "adata.obs['diff_batch'] = adata.obs['sampleID'].map(lambda x:x[0:x.find('-')]).values\n",
    "adata.obs['day'] = adata.obs['sampleID'].map(lambda x:x[x.rfind('-')+1:]).values\n",
    "\n",
    "adata = adata[~adata.obs['diff_batch'].isin([\"ZA57\"])]\n",
    "\n",
    "# Rename the protocols \n",
    "protocol_dict = {'ZA58':'batch-1', 'ZA59': 'batch-2', 'ZA60': 'batch-3'}\n",
    "adata.obs['diff_batch_2'] = adata.obs['diff_batch'].map(protocol_dict)\n",
    "\n",
    "# Remove unnecessary data from adata\n",
    "del adata.obsm\n",
    "adata.obs = adata.obs[['sampleID','diff_batch','diff_batch_2', 'day', 'nCount_HTO', 'nFeature_HTO']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute qc metrix\n",
    "adata.var['mt'] = adata.var_names.str.startswith('MT-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "fig, (ax0, ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 6,  figsize=(20,4), gridspec_kw={'wspace':0.5})\n",
    "ax0_dict = sc.pl.violin(adata,[\"pct_counts_mt\"], jitter=0.5, show=False, ax=ax0, stripplot=False)\n",
    "ax1_dict = sc.pl.violin(adata,['n_genes_by_counts'], jitter=0.5, show=False, ax = ax1, stripplot=False) \n",
    "ax2_dict = sc.pl.violin(adata,['total_counts'], jitter=0.5, show=False, ax = ax2, stripplot=False)\n",
    "ax3_dict = sns.histplot(adata.obs[\"n_genes_by_counts\"],  ax = ax3)\n",
    "ax4_dict = sns.histplot(adata.obs[\"total_counts\"], ax = ax4)\n",
    "ax5_dict = sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', show=False, ax=ax5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae159bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform fitering\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.filter_cells(adata, min_counts=1400)\n",
    "sc.pp.filter_cells(adata, max_counts=40000)\n",
    "sc.pp.filter_cells(adata, min_genes=1400)\n",
    "sc.pp.filter_cells(adata, max_genes=12300)\n",
    "adata = adata[adata.obs.pct_counts_mt <4, :] # Remove cells with high mito content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659469cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute qc metrix\n",
    "adata.var['mt'] = adata.var_names.str.startswith('MT-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "fig, (ax0, ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 6,  figsize=(20,4), gridspec_kw={'wspace':0.5})\n",
    "ax0_dict = sc.pl.violin(adata,[\"pct_counts_mt\"], jitter=0.5, show=False, ax=ax0, stripplot=False)\n",
    "ax1_dict = sc.pl.violin(adata,['n_genes_by_counts'], jitter=0.5, show=False, ax = ax1, stripplot=False) \n",
    "ax2_dict = sc.pl.violin(adata,['total_counts'], jitter=0.5, show=False, ax = ax2, stripplot=False)\n",
    "ax3_dict = sns.histplot(adata.obs[\"n_genes_by_counts\"],  ax = ax3)\n",
    "ax4_dict = sns.histplot(adata.obs[\"total_counts\"], ax = ax4)\n",
    "ax5_dict = sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', show=False, ax=ax5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ribo = adata.var_names.str.startswith(('RPL', \"RPS\"))\n",
    "mito = adata.var_names.str.startswith('MT-')\n",
    "remove = np.add(mito, ribo)\n",
    "keep = np.invert(remove)\n",
    "adata = adata[:,adata.var[keep].index]\n",
    "\n",
    "adata.layers[\"counts\"] = adata.X.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11964667-6f23-4ff5-8a2e-0994bd1e27a2",
   "metadata": {},
   "source": [
    "# Normalization, dimensionality reduction and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77392836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing and log-transforming the data\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "adata.layers['log_transformed'] = adata.X.copy()\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata)\n",
    "sc.pp.neighbors(adata, n_neighbors=15)\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.leiden(adata, resolution=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['Cell_types'] = 'Unassigned'\n",
    "\n",
    "\n",
    "optic = pd.Series(list(adata[adata.obs[\"leiden\"].isin(['6'])].obs.index), dtype=\"category\")\n",
    "adata.obs[\"Cell_types\"].loc[optic] = \"Optic area progenitors\"\n",
    "\n",
    "prog = pd.Series(list(adata[adata.obs[\"leiden\"].isin(['0','1','2'])].obs.index), dtype=\"category\")\n",
    "adata.obs[\"Cell_types\"].loc[prog] = \"Posterior tuberal progenitors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7b323-e868-4e57-b6f0-1f9841af15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_3_4_5 = adata[adata.obs.leiden.isin(['3','4','5'])].copy()\n",
    "sc.tl.leiden(adata_3_4_5, resolution=0.8)\n",
    "\n",
    "\n",
    "otp = pd.Series(list(adata_3_4_5[adata_3_4_5.obs[\"leiden\"].isin(['3','0'])].obs.index), dtype=\"category\")\n",
    "adata.obs[\"Cell_types\"].loc[otp] = \"OTP+ neurons\"\n",
    "\n",
    "pomc = pd.Series(list(adata_3_4_5[adata_3_4_5.obs[\"leiden\"].isin(['9','2'])].obs.index), dtype=\"category\")\n",
    "adata.obs[\"Cell_types\"].loc[pomc] = \"POMC+ neurons\"\n",
    "\n",
    "dlx = pd.Series(list(adata_3_4_5[adata_3_4_5.obs[\"leiden\"].isin(['5','8'])].obs.index), dtype=\"category\")\n",
    "adata.obs[\"Cell_types\"].loc[dlx] = \"DLX6-AS1+ neurons\"\n",
    "\n",
    "arc_pre = pd.Series(list(adata_3_4_5[adata_3_4_5.obs[\"leiden\"].isin(['6','4','10','1','7'])].obs.index), dtype=\"category\")\n",
    "adata.obs[\"Cell_types\"].loc[arc_pre] = \"Posterior tuberal precursors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705746a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the FOXG1+ population from the FOXG1- population in cluster 7\n",
    "adata_7 = adata[adata.obs.leiden.isin(['7'])].copy()\n",
    "sc.tl.leiden(adata_7, resolution=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9982163",
   "metadata": {},
   "outputs": [],
   "source": [
    "unassigned = pd.Series(list(adata_7[adata_7.obs[\"leiden\"].isin(['0'])].obs.index), dtype=\"category\")\n",
    "adata.obs[\"Cell_types\"].loc[unassigned] = \"Unassigned\"\n",
    "\n",
    "tele = pd.Series(list(adata_7[adata_7.obs[\"leiden\"].isin(['1'])].obs.index), dtype=\"category\")\n",
    "adata.obs[\"Cell_types\"].loc[tele] = \"Telencephalic progenitors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b5dbf-6b0a-4b4c-a2e0-ce1101aa0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_cell_types = ['#bb9c8a','#3586bd','#4f9e46','#eddb7e','#e85b3d','#ed9892','#fac384','#a4cde0']\n",
    "#palette_cell_types = ['#bb9c8a','#e85b3d','#4f9e46','#85c668','#3b89bf','#ed9892','#eddb7e','#a4cde0']\n",
    "\n",
    "with plt.rc_context({ \"figure.dpi\": 300, \"figure.figsize\": (5,4) }):\n",
    "    sc.pl.umap(adata, color=['Cell_types'],palette=palette_cell_types, ncols=2, use_raw=False, cmap='jet', frameon=False, colorbar_loc=None,size=18)\n",
    "    \n",
    "palette_batch=['#ff7f0eff', '#8c564bff', '#279e68ff']\n",
    "#with plt.rc_context({ \"figure.dpi\": 300, \"figure.figsize\": (5,4) }):\n",
    "    #sc.pl.umap(adata, color=['diff_batch'],palette=palette_batch, ncols=2, use_raw=False, cmap='jet', frameon=False, colorbar_loc=None,size=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66abff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write('../Data/adata_d16_annotated.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396202ea-7436-4719-a0cf-c4658dd28421",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read('../Data/adata_d16_annotated.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PYenv]",
   "language": "python",
   "name": "conda-env-.conda-PYenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
